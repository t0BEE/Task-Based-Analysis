\section{Related Work}

\subsection{Tasking}
\label{subsec:Tasking}
  Having the task construct as mean to parallelize a program allows to utilize irregular parallelism.
  Irregular parallelism is widely used these days and includes parallel execution of while loops or recursive function calls for instance.
  Tasking explicitly specifies independent units of work which can be executed in parallel.
  This enables a more dynamic way of parallelization.
  However, a disadvantage of this kind of parallelism is that it increases the complexity of a program and poor implementations can lead to an increased overhead.~\cite{Ayguade.2009}~\cite{LaGrone.2011}
  
  
  The used runtime system plays a crucial role when it comes to the application's performance using tasking. 
  For example, as the tasking construct creates several tasks which will be executed by threads, the performance of an application relies on the thread scheduler of the runtime system.
  The authors of \cite{LaGrone.2011} discuss different aspects of a runtime system using the task construct.
  The efficiency of such depends on the data structures which store unfinished tasks, manage task switching and regulate task creation.
  Additionally, the data structures to organize task synchronization and manage the memory footprint of a task are also important.
  The ideal way of work of the thread scheduler, for example, is to maximize concurrency, load balancing and data locality.
  This can be achieved by different ways to manage queue storing all tasks ready to be executed.
  Furthermore, the scheduler can be \textit{depth-first} or \textit{breadth-first}.
  Breadth-first means that child tasks created by the parent task and put into the queue to be scheduled at any time.
  Whereas breadth-first schedulers switch to child tasks directly after their creation and execute them.
  This leads to a smaller number of tasks in the queue and less concurrency opportunities.
  However, the data reuse increases.
 
 	
  The following subsections \ref{subsec:OpenMP} and \ref{subsec:HPX} introduce two runtime systems utilizing tasks.
  These will be compared in this work.


\subsection{Tasks in OpenMP}
\label{subsec:OpenMP}
  OpenMP includes the tasking model since version 3.0.
  Various directives for that purpose are being included since to specify and manage  tasks.
  However, OpenMP still differs between explicit and implicit tasks.
  Implicit tasks are created by parallel regions as side effect.
  The programmer does not need to specify or know about them.
  Explicit tasks on the other hand are defined by the programmer using the task directives.
  The simplest directive to define an explicit task is \texttt{omp task} and the enclosed code area is the task region.
  These are executed by any task in the current team whenever they are ready.~\cite{Ayguade.2009}~\cite{LaGrone.2011}

%MAYBE example implementation here - show the directives

  When a thread encounters a task directive the current data environment is captured.
  This environment and the block of code in the task region form the generated task.
  The variable scopes of a task region can be defined like in parallel regions.
  By adding the clauses \texttt{shared}, \texttt{private} or \texttt{firstprivate} to the task directive the declared variables are either shared among tasks or not.~\cite{Duran.2008}
  
  
  By default a thread is tied to a task as it begins to execute it.
  This means that this task is only allowed to be executed by one thread.
  However this thread can still execute other tasks in case it reaches task scheduling points and switches the execution to another task.
  The suspended task is put into the queue and has to wait until its tied thread is ready to continue its execution.
  This restriction can be avoided by defining the task \texttt{untied}.
  By doing so, load balancing is increased, but data locality is decreased.~\cite{Ayguade.2009}~\cite{LaGrone.2011}


  Tasking results in a more dynamic execution and might be unpredictable without explicit scheduling.
  For example the runtime system has either a depth- or breadth-first scheduler.
  Meaning that it either switches to the child task after creation or finishes the parent task first.
  The used OpenMP runtime system is responsible to decide.
  Explicit scheduling can be used to avoid this uncertainty.
  For instance, adding an \texttt{if}-clause to the task directive and evaluating it to false makes the encountering thread to suspend its current work and execute the child task immediately.
  Furthermore, explicit task scheduling is possible by using the \texttt{taskwait} and \texttt{barrier} directives.
  \texttt{taskwait} suspends the encountering task region and forces it to wait for all child tasks to complete.
  Additionally \texttt{taskgroup} defines a task region which will be executed and at the end the current task has to wait for all its child and their descendants.~\cite{Qawasmeh.2014}~\cite{Furlinger.2009}


\subsection{HPX}
\label{subsec:HPX}
\subsubsection{HPX}
  \cite{Kaiser.2014}
  - general purpose C++ runtime system for parallel and distributed applications of any scale
  - innovative mixture of global system-wide address space, fine grain parallelism, and lightweight synchronization
    + implicit message driven computation
    + semantic equivalent of local and remote execution
    + explicit support for accelerators such as GPGPUs
  - aims to resolve scalability / resiliency / power efficiency / runtime adaptive resource management in the evolve from Peta- to Exascale systems
  
\cite{Kaiser.2009}
  - introduce a new model of parallel execution --> Parallex
    - efficiency / scalability
    
  - HPX = run time system supporting the ParalleX model
  
--> folgende sind groÃŸe Vergleiche zu MPI ---
    - dynamically schedule multiple threads moving the work to the data
     -> instead of statically designated processes synchroized by message passing
    - use local synchronization and global asynchronicity (MPI uses messages as synchronization)
    - Global barriers are essentially eliminated and instead replaced by
lightweight Local Control Objects (LCOs) -> futures / mutexes
    - key to efficiency and latency hiding is the message-driven work-queue
	  -> apply user tasks to physical processing resources
	- uses active global address space (AGAS)
	  - allows to move virtual objects in physical space without changing virtual names
	  ---
	- conventiionally 1 process = 1 processor
	  -> ParalleX, use \textit{parallel processes}: map a process to multiple cores, allow many concurrent threads and child processes
	- use a thread manager implemented as FCFS scheduler 
	  - OS threads work from a single queue of tasks 
	  --> sufficient for small amount of concurrent OS threads
	  --> there is work on a more scalable , work stealing scheduler using one queue per OS thread (core)
	  

\subsubsection{Tasks in HPX}
\cite{TheSTEARGroup.2020}
  - HPX allows the same tasking method as the C++ standard library --> using async and futures
    - lightweight threads are used which have faster context switches and smaller stacks
    - async: launches a task asynchronously
    - future<T>: represents a value of type T which will be available in the future
    - continuation - then: take a function to run after the task is done

  - future: acts as a placeholder for a result not known yet
    --> the computation for that value is not yet completed
    --> using the get() method blocks the calling thread and it passively waits until the value of the future is available
    - when a future is created it spawns a new HPX-Thread and places it on the thread queue


\subsection{hpxMP}
\cite{TianyiZhang.2019}
- introduction of hpxMP

\cite{Zhang.2192020}
- OpenMP 5 tasks in hpxMP


    
\subsection{Benchmark Algorithm}
- Barcelona OpenMP Task Suite (BOTS)
	- aim of the suite is to provide a collection of benchmarks that would allow vendors to test the impact of different implementation decisions in a multicore architecture
	- 9 benchmarks
		> Alignment: align protein sequences against every other sequence using a special algorithm
		> FFT: Fast Fourier Transformation
		> Fibonacci: calculation of the nth number in the Fibonacci sequence
		> Floorplan: compute the optimal floorplan distribution of a number of cells
		> Health: simulate the Columbian Health Care System
		> N Queens: the n-queen problem, to find placements of queens on a chessboard under special conditions
		> Sort: parallel execution of merge sort
		> SparseLU: LU matrix factorization over sparse matrices
		> Strassen: hierarchical decomposition of a matrix for multiplication of large dense matrices
	--> different version of each benchmark and some with cut-off version to avoid high amount of tasks
	

	- Fibonacci --> high amount of tasks, having the scheduling as the main part of the workload
	- MergeSort --> easy to implement, good use case and high number of tasks
	
