\section{Implementation \& Design}
  For this paper Fibonacci and the Sort algorithm are chosen to be implemented from BOTS, as introduced in subsection \ref{subsec:BOTS}.
  Additionally, a generic algorithm is implemented.
  All three are implemented using OpenMP, HPX and in a sequential way.
  
  \paragraph{Fibonacci}
  \textit{\textbf{TODO --- Look up fibonacci algorithm}}
  The algorithm can spawn a high amount of tasks with small workload.
  The scheduler is the most significant point when it comes to its performance.
  
  \paragraph{Merge Sort}
  \textit{\textbf{TODO --- Look up merge sort}}
  The Sort algorithm is slightly adjusted to a normal merge sort.
  It is a suitable use case, easy to implement and can also spawn a high number of tasks.

  \paragraph{Generic Algorithm}
  The aim of this algorithm is to enable task size adjustment and allow to define the number of tasks.
  
  The algorithm uses two vectors which sizes are defined at the building process.
  Suggested is a size of 1024 for each.
  First of all one vector is filled by randomized floating point numbers.
  To compare each run a deterministic seed for the random numbers is chosen.
  In each turn the element of a vector is equal to a calculation on the element of the other vector.
  The sinus function is calculated on the element before it is multiplied by ten and adjusted to an absolute value.
  This turns are repeated a defined number of times.
  After the last turn is executed, each elements of the last calculated vector are summed up.

  The task size can be adapted by parameters and defines how many vector elements are calculated by a task.
  The task size furthermore defines how many tasks are used per run.
  This number is equal to the vector size divided by the task size.
  As each turn depends on the execution of the previous turn, the number of dependencies can be increased by using more tasks per turn.
		
	
	
\subsection{Optimization}
	
	\cite{LaGrone.2011}
	--> task has an if clause evaluated to false will directly continue with the generated task --> depth-first
	--> untied tasks (balancing) vs tied (data locality)
	--> (maybe) use taskwait for less scheduling overhead --> depth-first
	--> cutoff, regulating task creation, if condition is not met execute tasks immediately and do not place them on the queue
		--> create new OMP\_TASK\_CREATE\_COND environment variable
		
    --> does the shared variable directive decrease the work for task creation???
    
    --> a nowait directive at the omp single
    
    \cite{MKlemm.2018}
 --> directives to optimize
 	-->taskyield - suspend the current task in favor of execution of a different task
 	--> if - in case it is false the task is executed immediately
 	--> mergeable - A task for which the data environment, is the same as that of its generating task region
 	--> final - force all child tasks to become final and included
 		--> if true --> child tasks become included --> means that the tasks are also executed by the parent task


  \cite{TheSTEARGroup.2020}
    - HPX --> Performance counters to identify bottlenecks
    - HPX exposes special API functions to allow one to create, manage and read the counter data
    - all performance counter instances have a unique name to access the counter